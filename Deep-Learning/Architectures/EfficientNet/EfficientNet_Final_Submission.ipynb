{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95MuxrtRhNNE"
      },
      "source": [
        "## Mounting google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYqOoDhJLno4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt3dWfqvdgyv"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supporting Classes and Functions"
      ],
      "metadata": {
        "id": "OikA-kOYbNCo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGYdgbK5dc1w"
      },
      "outputs": [],
      "source": [
        "def train_model(model,      # Model\n",
        "                dataloader, # Dataloader for the training data\n",
        "                device,     # Choice between CPU and GDU\n",
        "                criterion,  # Loss function\n",
        "                optimizer   # Optimizer \n",
        "                ):\n",
        "    model.train()\n",
        "    for x_train, y_labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x_train.to(device))\n",
        "        loss = criterion(out, y_labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i75-d7tad1wx"
      },
      "outputs": [],
      "source": [
        "def eval_model(model,     # Model\n",
        "               dataloader,# Dataloader for the training data\n",
        "               device,    # Choice between CPU and GDU\n",
        "               criterion  # Loss function\n",
        "               ):\n",
        "    loss_arr = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x_data, y_labels in dataloader:\n",
        "            out = model(x_data.to(device))\n",
        "            loss = criterion(out, y_labels.to(device))\n",
        "            loss_arr.append(loss.item())\n",
        "            y_pred.append(out.detach().cpu())\n",
        "            y_true.append(y_labels.detach().cpu())\n",
        "    loss_arr = sum(loss_arr) / len(loss_arr)\n",
        "    # Compute Accuracy \n",
        "    y_pred = torch.cat(y_pred)\n",
        "    y_true = torch.cat(y_true)\n",
        "    _, y_pred = torch.max(y_pred, 1)\n",
        "    accuracy =  accuracy_score(y_pred, y_true)\n",
        "    return accuracy, loss_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAnGGXvjpEpn"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,   # Number of input channels.\n",
        "                 out_channels,  # Number of output channels.\n",
        "                 kernel_size,   # Kernel size for the CNN layer.\n",
        "                 activation,    # Activation function.\n",
        "                 bn_epsilon,    # Batch normalization epsilon value.\n",
        "                 bn_momentum,   # Batch normalization momentum value. \n",
        "                 stride = 1,    # Stride of CNN layer.\n",
        "                 groups = 1,    # Number of groups for CNN layer.\n",
        "                 ):\n",
        "      \n",
        "        super(CNNBlock, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Conv2d(  in_channels   =   in_channels,\n",
        "                                      out_channels  =   out_channels,\n",
        "                                      kernel_size   =   kernel_size,\n",
        "                                      stride        =   stride,\n",
        "                                      padding       =   kernel_size//2,\n",
        "                                      groups        =   groups          )\n",
        "\n",
        "        self.batch_norm_layer = nn.BatchNorm2d( out_channels,\n",
        "                                                eps      =   bn_epsilon,\n",
        "                                                momentum =   bn_momentum )\n",
        "        self.activation_layer = activation\n",
        "\n",
        "    def out_channels(self):\n",
        "        return self.conv_layer.out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.batch_norm_layer(x)\n",
        "        if self.activation_layer is not None:\n",
        "            x = self.activation_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGZFdygspHsD"
      },
      "outputs": [],
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "        self.operation = self.swish_fcn\n",
        "\n",
        "    def swish_fcn(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.operation(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vJzc-Gxp60d"
      },
      "outputs": [],
      "source": [
        "class Stochastic_depth(nn.Module):\n",
        "    def __init__(self,\n",
        "                 rate=0.5 # Dropping rate.\n",
        "                 ):\n",
        "        super(Stochastic_depth, self).__init__()\n",
        "        self.keep_prob = 1 - rate\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Drop only during training\n",
        "        if self.training:\n",
        "          # Create a random tensor\n",
        "            rand_tensor = self.keep_prob + torch.rand([x.size(0), 1, 1, 1],\n",
        "                                                        dtype=x.dtype,\n",
        "                                                        device=x.device)\n",
        "            # To have zeros and ones only in the tensor\n",
        "            out_tensor = torch.floor(rand_tensor)\n",
        "            return torch.mul(torch.div(x, self.keep_prob), out_tensor)\n",
        "        else:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQLZCllCqZyC"
      },
      "outputs": [],
      "source": [
        "# Squeeze Excitation block\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels, # Number of input channels for the squeeze excitation block.\n",
        "                 reduced_dim, # Number of reduction channels for the squeeze and excitation block.\n",
        "                 activation   # Activation function for the squeeze and excitation block.\n",
        "                 ):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.reduction_layer = nn.Conv2d( in_channels   =   in_channels,\n",
        "                                          out_channels  =   reduced_dim,\n",
        "                                          kernel_size   =   1)\n",
        "        \n",
        "        self.restoration_layer = nn.Conv2d( in_channels   = reduced_dim,\n",
        "                                            out_channels  = in_channels,\n",
        "                                            kernel_size   = 1 )\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = x\n",
        "        x   = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x   = self.reduction_layer(x)\n",
        "        x   = self.activation(x)\n",
        "        x   = self.restoration_layer(x)\n",
        "        x   = torch.sigmoid(x)\n",
        "        return torch.mul(inp, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qgh_EcgGWqk"
      },
      "outputs": [],
      "source": [
        "class InvertedResidualBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,       # Number of input channels\n",
        "                 out_channels,      # Number of output channels\n",
        "                 kernel_size,       # kernal size\n",
        "                 stride,            # stride length\n",
        "                 expansion_factor,  # expansion factor\n",
        "                 activation,        # activation type\n",
        "                 bn_epsilon,        # batch normalization epsilon\n",
        "                 bn_momentum,       # batch normalization momentum\n",
        "                 se_size,           # Squeeze and excitation layer reduction layer size\n",
        "                 drop_connect_rate  # rate of drop connect\n",
        "                 ):\n",
        "        super(InvertedResidualBlock, self).__init__()\n",
        "\n",
        "        exp_channels = in_channels * expansion_factor\n",
        "        self.activation = activation\n",
        "\n",
        "        # expansion convolution\n",
        "        if expansion_factor != 1:\n",
        "            self.expanded_conv = CNNBlock(  in_channels   = in_channels,\n",
        "                                          out_channels  = exp_channels,\n",
        "                                          kernel_size   = 1,\n",
        "                                          activation    = self.activation,\n",
        "                                          bn_epsilon    = bn_epsilon,\n",
        "                                          bn_momentum   = bn_momentum )\n",
        "        else:\n",
        "            self.expanded_conv = None\n",
        "\n",
        "        # depth-wise convolution\n",
        "        self.deepwise_conv = CNNBlock(  in_channels   = exp_channels,\n",
        "                                  out_channels  = exp_channels,\n",
        "                                  kernel_size   = kernel_size,\n",
        "                                  stride        = stride,\n",
        "                                  groups        = exp_channels,\n",
        "                                  activation    = self.activation,\n",
        "                                  bn_epsilon    = bn_epsilon,\n",
        "                                  bn_momentum   = bn_momentum )\n",
        "\n",
        "        self.se = SEBlock(  in_channels = exp_channels,\n",
        "                            reduced_dim = se_size,\n",
        "                            activation  =self.activation )\n",
        "        \n",
        "        self.drop_connect = Stochastic_depth( rate = drop_connect_rate )\n",
        "\n",
        "        # Enable of stochastic depth\n",
        "        if in_channels == out_channels and stride == 1:\n",
        "            self.skip_enabled = True\n",
        "        else:\n",
        "            self.skip_enabled = False\n",
        "\n",
        "        # projection convolution\n",
        "        self.projection_conv = CNNBlock( in_channels   = exp_channels,\n",
        "                                      out_channels  = out_channels,\n",
        "                                      kernel_size   = 1,\n",
        "                                      activation    = None,\n",
        "                                      bn_epsilon    = bn_epsilon,\n",
        "                                      bn_momentum   = bn_momentum )\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = x\n",
        "        if self.expanded_conv is not None:\n",
        "            x = self.expanded_conv(x)\n",
        "        # depth-wise convolution\n",
        "        x = self.deepwise_conv(x)\n",
        "        # squeeze-and-excitation layer\n",
        "        x = self.se(x)\n",
        "        # projection convolution\n",
        "        x = self.projection_conv(x)\n",
        "        # drop-connect applied only if skip connection enabled\n",
        "        if self.skip_enabled:\n",
        "          x = self.drop_connect(x)\n",
        "          x = x + inp\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9sxqpJaLpES"
      },
      "outputs": [],
      "source": [
        "# Number of layers per each MBCOnv stage\n",
        "class MBConvLayersPerStage(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_layers,          # Number of layers per each stage.\n",
        "                 in_channels,         # Number of input channels for the first layer in the stage.\n",
        "                 out_channels,        # Number of output channels for the first layer in the stage.\n",
        "                 stride,              # Stride\n",
        "                 se_ratio,            # Squeeze and excitation ratio\n",
        "                 drop_connect_rates,  # Drop connect rates\n",
        "                 kernel_size,         # Kernel\n",
        "                 expansion_factor,    # Expansion factor for the width of the MBConv\n",
        "                 activation,          # Activation function\n",
        "                 bn_epsilon,          # Batch normalization epsilon \n",
        "                 bn_momentum          # Batch normalization momentum\n",
        "                 ):\n",
        "      \n",
        "        super(MBConvLayersPerStage, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(self.num_layers):\n",
        "            se_size = max(1, in_channels // se_ratio)\n",
        "            layer = InvertedResidualBlock(\n",
        "                                in_channels=in_channels,\n",
        "                                out_channels=out_channels,\n",
        "                                stride=stride,\n",
        "                                se_size=se_size,\n",
        "                                drop_connect_rate=drop_connect_rates[i],\n",
        "                                kernel_size = kernel_size,\n",
        "                                expansion_factor = expansion_factor,\n",
        "                                activation = activation,\n",
        "                                bn_epsilon = bn_epsilon,\n",
        "                                bn_momentum = bn_momentum)\n",
        "            self.layers.append(layer)\n",
        "            # Set stride 1 for the rest of the MBConv Layer and the output of \n",
        "            # last layer is the same as the input of the next layer.\n",
        "            stride = 1\n",
        "            in_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Completely taken from https://github.com/abhuse/pytorch-efficientnet\n",
        "def round_filters(filters, width_coefficient, depth_divisor=8):\n",
        "    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
        "    min_depth = depth_divisor\n",
        "\n",
        "    filters *= width_coefficient\n",
        "    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_filters < 0.9 * filters:\n",
        "        new_filters += depth_divisor\n",
        "    return int(new_filters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFD5ZBoYqFfE"
      },
      "outputs": [],
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    # (width_coefficient  ,depth_coefficient  ,dropout_rate ,in_spatial_shape(resolution))\n",
        "    coefficients = [\n",
        "        (1.0              ,1.0                ,0.2          ,224),\n",
        "        (1.0              ,1.1                ,0.2          ,240),\n",
        "        (1.1              ,1.2                ,0.3          ,260),\n",
        "        (1.2              ,1.4                ,0.3          ,300),\n",
        "        (1.4              ,1.8                ,0.4          ,380),\n",
        "        (1.6              ,2.2                ,0.4          ,456),\n",
        "        (1.8              ,2.6                ,0.5          ,528),\n",
        "        (2.0              ,3.1                ,0.5          ,600),\n",
        "    ]\n",
        "\n",
        "    # block_repeat  ,kernel_size  ,stride ,expansion_factor ,input_channels ,output_channels  ,se_ratio\n",
        "    stage_args = [\n",
        "        [1          ,3            ,1      ,1                ,32             ,16               ,4],\n",
        "        [2          ,3            ,2      ,6                ,16             ,24               ,4],\n",
        "        [2          ,5            ,2      ,6                ,24             ,40               ,4],\n",
        "        [3          ,3            ,2      ,6                ,40             ,80               ,4],\n",
        "        [3          ,5            ,1      ,6                ,80             ,112              ,4],\n",
        "        [4          ,5            ,2      ,6                ,112            ,192              ,4],\n",
        "        [1          ,3            ,1      ,6                ,192            ,320              ,4],\n",
        "    ]\n",
        "\n",
        "    n_stages = 6 # number of MBCovs\n",
        "\n",
        "    def __init__(self,\n",
        "                 b,\n",
        "                 in_channels=3,         # Number of input channels.\n",
        "                 n_classes=1000,        # Number of classes.\n",
        "                 activation=Swish(),    # Activation function\n",
        "                 drop_connect_rate=0.2, # Drop connect rates\n",
        "                 bn_epsilon=1e-3,       # Batch normalization epsilon \n",
        "                 bn_momentum=0.01       # Batch normalization momentum \n",
        "                 ):\n",
        "      \n",
        "        super(EfficientNet, self).__init__()\n",
        "\n",
        "        self.b = b\n",
        "        self.in_channels = in_channels\n",
        "        self.activation = activation\n",
        "        self.drop_connect_rate = drop_connect_rate\n",
        "        self.width_coefficient = EfficientNet.coefficients[self.b][0]\n",
        "        self.depth_coefficient = EfficientNet.coefficients[self.b][1]\n",
        "        self.dropout_rate      = EfficientNet.coefficients[self.b][2]\n",
        "\n",
        "        # initial convolution\n",
        "        init_conv_out_channels = round_filters(32, self.width_coefficient)\n",
        "\n",
        "        self.initial_conv = CNNBlock(\n",
        "                                   in_channels  =   self.in_channels,\n",
        "                                   out_channels =   init_conv_out_channels,\n",
        "                                   kernel_size  =   3,\n",
        "                                   stride       =   2,\n",
        "                                   activation   =   self.activation,\n",
        "                                   bn_epsilon   =   bn_epsilon,\n",
        "                                   bn_momentum  =   bn_momentum\n",
        "                                   )\n",
        "       \n",
        "\n",
        "        self.stages = nn.ModuleList()\n",
        "        # Variable to keep track of the current layer number\n",
        "        stage_curr_layer = 0\n",
        "\n",
        "        # Compute the drop connect rates based on the scaled layers\n",
        "        # Get the number of layers of each MBConv block and add them together\n",
        "        total_num_layers_all = 0\n",
        "        for i in range(self.n_stages):\n",
        "            total_num_layers_all += int(ceil(self.depth_coefficient * self.stage_args[i][0]))\n",
        "        # Array of drop connect\n",
        "        dc_rates= [self.drop_connect_rate * i / total_num_layers_all\n",
        "                for i in range(total_num_layers_all)]\n",
        "      \n",
        "        for idx in range(self.n_stages):\n",
        "            # Get the kernel size of the stage.\n",
        "            kernel_size = EfficientNet.stage_args[idx][1]\n",
        "            # Get the stride of the stage.\n",
        "            stride = EfficientNet.stage_args[idx][2]\n",
        "            # Get the expansion factor of the stage.\n",
        "            expansion_factor = EfficientNet.stage_args[idx][3]\n",
        "            # Get the squeeze excitation factor of the stage.\n",
        "            stage_se_ratio = EfficientNet.stage_args[idx][6]\n",
        "            # Get the scaled input channels of the stage.\n",
        "            # Get the baseline number of input channels, and then  scale it with the width scaling.\n",
        "            stage_in_channels = EfficientNet.stage_args[idx][4] \n",
        "            stage_in_channels =  round_filters(stage_in_channels, self.width_coefficient)\n",
        "            # Get the scaled output channels of the stage.\n",
        "            # Get the baseline number of output channels, and then  scale it with the width scaling.\n",
        "            stage_out_channels = EfficientNet.stage_args[idx][5]\n",
        "            stage_out_channels = round_filters(stage_out_channels, self.width_coefficient)\n",
        "            # Get Scaled number of layers of each stage.\n",
        "            stage_num_layers = int(ceil(self.depth_coefficient * EfficientNet.stage_args[idx][0]))\n",
        "            # Get the DC rates from the current layer to (current layer + state number of layers).\n",
        "            stage_dc_rates = dc_rates[stage_curr_layer:stage_curr_layer + stage_num_layers]\n",
        "            # Create the MBConv block and append to the store stages array.\n",
        "            MBConv_stage = MBConvLayersPerStage(\n",
        "                              num_layers          =   stage_num_layers,\n",
        "                              in_channels         =   stage_in_channels,\n",
        "                              out_channels        =   stage_out_channels,\n",
        "                              stride              =   stride,\n",
        "                              se_ratio            =   stage_se_ratio,\n",
        "                              drop_connect_rates  =   stage_dc_rates,\n",
        "                              kernel_size         =   kernel_size,\n",
        "                              expansion_factor    =   expansion_factor,\n",
        "                              activation          =   self.activation,\n",
        "                              bn_epsilon          =   bn_epsilon,\n",
        "                              bn_momentum         =   bn_momentum\n",
        "                              )\n",
        "            \n",
        "            self.stages.append(MBConv_stage)\n",
        "            # Change the point of the current layer to the start of the next stage.\n",
        "            stage_curr_layer += stage_num_layers\n",
        "\n",
        "        # Compute the number of input channels of the last convolutional block\n",
        "        # which is the number of output channel of the projection layer of the last\n",
        "        # stage. >> Already scaled.\n",
        "        in_channels_final_conv = self.stages[-1].layers[-1].projection_conv.out_channels()\n",
        "        # Compute the number of output channels which is 1280 as per the paper\n",
        "        # with scaling.\n",
        "        out_channels_final_conv = round_filters(1280, self.width_coefficient)\n",
        "        # Define the final convolutional layer.\n",
        "        self.final_conv_layer = CNNBlock(in_channels  =   in_channels_final_conv,\n",
        "                                   out_channels       =   out_channels_final_conv,\n",
        "                                   kernel_size        =   1,\n",
        "                                   activation         =   self.activation,\n",
        "                                   bn_epsilon         =   bn_epsilon,\n",
        "                                   bn_momentum        =   bn_momentum)\n",
        "        # Define the final dropout layer.\n",
        "        self.dropout_layer = nn.Dropout(p=self.dropout_rate)\n",
        "        # Define the final average pooling layer.\n",
        "        self.avgPool_layer = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # Define the final fully connected layer for classification.\n",
        "        self.fc_layer = nn.Linear(out_channels_final_conv, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        for stage in self.stages:\n",
        "          x = stage(x)\n",
        "        x = self.final_conv_layer(x)\n",
        "        x = self.avgPool_layer(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_layer(x)\n",
        "        x = self.fc_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pqDVq7mBR3-"
      },
      "outputs": [],
      "source": [
        "def load_dataset(Dataset,img_size):\n",
        "\n",
        "  n_classes = 0\n",
        "\n",
        "  if (Dataset == 'CIFAR10'):\n",
        "    #CIFAR10\n",
        "    n_classes = 10\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(img_size, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    transform_validation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    dataset_train = datasets.CIFAR10(root='./data',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform_train,\n",
        "                                      )\n",
        "    dataset_train_val = datasets.CIFAR10(root='./data',\n",
        "                                          train=True,\n",
        "                                          download=True,\n",
        "                                          transform=transform_validation,\n",
        "                                          )\n",
        "    dataset_validation = datasets.CIFAR10(root='./data',\n",
        "                                          train=False,\n",
        "                                          download=True,\n",
        "                                          transform=transform_validation,\n",
        "                                          )\n",
        "  elif(Dataset == 'CIFAR100'):\n",
        "    #CIFAR100\n",
        "    n_classes = 100\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(img_size, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.507075, 0.48655024, 0.44091907],\n",
        "                            std=[0.26733398, 0.25643876, 0.2761503]),\n",
        "    ])\n",
        "\n",
        "    transform_validation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5070754,  0.48655024, 0.44091907],\n",
        "                            std=[0.26733398, 0.25643876, 0.2761503]),\n",
        "    ])\n",
        "\n",
        "    dataset_train = datasets.CIFAR100(root='./data',\n",
        "                                      train=True,\n",
        "                                      download=True,\n",
        "                                      transform=transform_train,\n",
        "                                      )\n",
        "    dataset_train_val = datasets.CIFAR100(root='./data',\n",
        "                                          train=True,\n",
        "                                          download=True,\n",
        "                                          transform=transform_validation,\n",
        "                                          )\n",
        "    dataset_validation = datasets.CIFAR100(root='./data',\n",
        "                                          train=False,\n",
        "                                          download=True,\n",
        "                                          transform=transform_validation,\n",
        "                                          )\n",
        "  else:\n",
        "    raise Exception(\"Sorry, Wrong dataset entry\")\n",
        "\n",
        "  dataloader_train = DataLoader(dataset_train,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=num_workers,\n",
        "                              )\n",
        "  dataloader_train_val = DataLoader(dataset_train_val,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=num_workers,\n",
        "                                    )\n",
        "  dataloader_validation = DataLoader(dataset_validation,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=num_workers,\n",
        "                                    )\n",
        "\n",
        "  return dataloader_train ,dataloader_train_val ,dataloader_validation ,n_classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Training"
      ],
      "metadata": {
        "id": "HcdhoiKBbVw0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yENnWeo1d9OX"
      },
      "outputs": [],
      "source": [
        "# Initialize training parameters.\n",
        "model_index = 0 # 0 >> EfficientNet-B0, 1 >> EfficientNet-B1, 2 >> EfficientNet-B2 etc\n",
        "batch_size = 128 # 128 for CIFAR10 and 64 for CIFAR100\n",
        "max_epoch = 100\n",
        "num_workers = psutil.cpu_count()\n",
        "img_size = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load dataset\n",
        "dataloader_train ,dataloader_train_val ,dataloader_validation ,n_classes = load_dataset('CIFAR10',img_size)\n",
        "\n",
        "# Model definition\n",
        "model = EfficientNet(b=model_index,\n",
        "                     n_classes=n_classes,\n",
        "                     )\n",
        "# Change to CPU/CUDA\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30,60,90], gamma=0.1)\n",
        "\n",
        "# Create a dictionary for data collection.\n",
        "results = {\n",
        "    \"train_loss\": [],\n",
        "    \"valid_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"valid_acc\": [],\n",
        "}\n",
        "# Time logging start\n",
        "start_time = datetime.now()\n",
        "# Training/Testing loop\n",
        "for epoch in range(0, max_epoch):\n",
        "  now = datetime.now()\n",
        "  train_model(model=model,\n",
        "              dataloader=dataloader_train,\n",
        "              device=device,\n",
        "              criterion=criterion,\n",
        "              optimizer=optimizer)\n",
        "  # Evaluation of validation data\n",
        "  train_accuracy, train_loss = eval_model(model=model,\n",
        "                                  dataloader=dataloader_train_val,\n",
        "                                  device=device,\n",
        "                                  criterion=criterion)\n",
        "  # Evaluation of testing data\n",
        "  valid_accuracy, valid_loss = eval_model(model=model,\n",
        "                              dataloader=dataloader_validation,\n",
        "                              device=device,\n",
        "                              criterion=criterion)\n",
        "  # Appending to results dictionary\n",
        "  results[\"train_loss\"].append(train_loss)\n",
        "  results[\"train_acc\"].append(train_accuracy)\n",
        "  results[\"valid_loss\"].append(valid_loss)\n",
        "  results[\"valid_acc\"].append(valid_accuracy)\n",
        "  # Step the scheduler\n",
        "  scheduler.step(valid_accuracy)\n",
        "  # Print data\n",
        "  s = \"Epoch:{}/{} | Loss Training/Validation: {:.4f}/{:.4f}\".format(epoch, max_epoch, train_loss, valid_loss)\n",
        "  s += \" | Accuracy Training/Validation: {:.4f}/{:.4f}\".format(train_accuracy, valid_accuracy)\n",
        "  s += \" Time taken per epoch: +{}\".format(datetime.now() - now)\n",
        "  print(s)\n",
        "\n",
        "print(\"Total elapsed time: {}\".format(datetime.now() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ZkVt0GeDKz"
      },
      "outputs": [],
      "source": [
        "# Number of model parameters\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5kphvg2e0OA"
      },
      "outputs": [],
      "source": [
        "# Plot the loss vs Accuracy\n",
        "epochs = list(range(max_epoch))\n",
        "lines = plt.plot(epochs, results[\"train_loss\"], epochs, results[\"valid_loss\"])\n",
        "plt.legend(('Train', 'Validation'))\n",
        "plt.title('Loss chart')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWlbIUL9e2um"
      },
      "outputs": [],
      "source": [
        "# Plot the epoch vs Accuracy\n",
        "epochs = list(range(max_epoch))\n",
        "lines = plt.plot(epochs, results[\"train_acc\"], epochs, results[\"valid_acc\"])\n",
        "plt.legend(('Train', 'Validation'))\n",
        "plt.title('Accuracy chart')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}